{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPE 351 Assignment 2\n",
    "\n",
    "We'll first import the necessary python packages to run the code in the\n",
    "notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages.\n",
    "from os.path import dirname, join, realpath\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "\n",
    "    return not hasattr(main, \"__file__\")\n",
    "\n",
    "\n",
    "if is_interactive():\n",
    "    script_dir = dirname(realpath(\"__file__\"))\n",
    "else:\n",
    "    script_dir = dirname(realpath(__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Image Classification using CNN (50 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "epochs_count = 2\n",
    "classes_count = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionProductDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.fashion_products_data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fashion_products_data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = join(\n",
    "            self.root_dir, self.fashion_products_data_frame.iloc[idx, 0]\n",
    "        )\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.fashion_products_data_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype(\"float\").reshape(-1, 2)\n",
    "        sample = {\"image\": image, \"landmarks\": landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_frame = pd.read_csv(join(script_dir, \"data/train.csv\"))\n",
    "test_data_frame = pd.read_csv(join(script_dir, \"data/test.csv\"))\n",
    "training_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d1d4a31fd394edaf21d74294ba63853de24e6c25ad80bd4e86b4df595896c02"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('cmpe-351-_rWzjxJw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
