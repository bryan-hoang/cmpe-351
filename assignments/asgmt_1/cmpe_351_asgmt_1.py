# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.13.6
#   kernelspec:
#     display_name: 'Python 3.10.0 64-bit (''cmpe-351-_rWzjxJw'': pipenv)'
#     language: python
#     name: python3
# ---

# %% [markdown]
# # CMPE 351 Assignment 1

# %%
# Importing packages.
from os.path import dirname, join, realpath

import matplotlib.pyplot as plt
import missingno as msno
import numpy as np

# Data collection and processing
import pandas as pd

# Data visualization
import seaborn as sns
import statsmodels.api as sm
from scipy.stats import pearsonr
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

plt.rcParams["ytick.labelsize"] = 7


def is_interactive():
    import __main__ as main

    return not hasattr(main, "__file__")


if is_interactive():
    script_dir = dirname(realpath("__file__"))
else:
    script_dir = dirname(realpath(__file__))

# Mainly generated by Github Copilot.
def missing_data_summary(df):
    """
    Function to summarize missing data in a dataframe.
    """
    # Calculate missing data
    missing_data = df.isnull().sum()
    # Calculate percentage of missing data
    missing_data_percent = (missing_data / df.shape[0]) * 100
    # Print summary
    return pd.concat(
        [missing_data, missing_data_percent],
        axis=1,
        keys=["Missing", "Percent"],
    )


# To make accessing through keys easier/more consistent.
def normalize_column_names(df):
    return df.rename(
        columns=lambda x: x.strip().lower().replace(" ", "_"), inplace=True
    )


# Source: https://stackoverflow.com/a/37871635/8714233
def boxplot_sorted(df, by, column):
    descending_median_order = (
        df.groupby(by)[column].median().sort_values(ascending=False).index
    )

    sns.boxplot(
        x=column,
        y=by,
        data=df,
        order=descending_median_order,
    )


# %%
raw_house_prices_1_df = pd.read_csv(
    join(script_dir, "data/2020_brooklyn.csv"), thousands=","
)
raw_house_prices_1_df.head()

# %%
raw_house_prices_2_df = pd.read_csv(
    join(script_dir, "data/2020_queens.csv"), thousands=","
)
raw_house_prices_2_df.head()

# %%
normalize_column_names(raw_house_prices_1_df)
normalize_column_names(raw_house_prices_2_df)

# %% [markdown]
# ## Part 1: Feature Selection and Multicollinearity Analysis

# %% [markdown]
# ### Answer to RQ1.1
#
# Splitting the training and test data.

# %%
training_data_1_df, test_data_1_df = train_test_split(
    raw_house_prices_1_df, test_size=0.1
)

training_data_2_df, test_data_2_df = train_test_split(
    raw_house_prices_2_df, test_size=0.1
)

training_data = pd.concat([training_data_1_df, training_data_2_df])

# %% [markdown]
# ### Answer to RQ1.2
#
# Let's first do some data exploration.

# %% [markdown]
# How many variables/attributes does the dataset have? 21

# %%
training_data.info()

# %%
training_data.describe()

# %% [markdown]
# How much missing data is there?

# %%
print(missing_data_summary(training_data))
msno.bar(training_data)

# %% [markdown]
# About 23% of the sale price values are missing/not known. Given that this is the target of the regression analysis, the missing values won't help in building the model. Also, Sale prices of $0 indicates that there was a transfer of ownership without a cash consideration, which also doesn't help contribute to building the model. Therefore, these rows can be safely removed.

# %%
training_data = training_data.dropna(subset=["sale_price"])
training_data = training_data[training_data["sale_price"] != 0]

msno.bar(training_data)

# %%
# Observing potential outliers and skewness in the data.
sns.histplot(training_data["sale_price"], log_scale=True, bins=25)

# %%
# Dealing with the positive skewness
print(training_data["sale_price"].skew())
training_data["sale_price"] = training_data["sale_price"] ** (1 / 5.2)
print(training_data["sale_price"].skew())
sm.qqplot(training_data["sale_price"], line="s")

# %% [markdown]
# - Given that easement has 100% missing values, the feature will be removed from the data set.
# - A house' address also somewhat acts as an ID, which means it's likely not relevant to the house' price, despite it being possible for multiple apartments to have the same address.
# - A similar argument can be made for zip code due to its uniqueness within the city.
# - Since the dataset generated from two different boroughs, it won't have much of an impact on the individual test datasets from particular boroughs.
# - Tax class, block, and lot may have been subject to change since the date of the sale, and share overlap with other building class related attributes.
# - Similar argument for tax class at time of sale.
# - Building class at present would be very similar to build class at time of purchase, with the downside of having less to no influence on its previous sale price.
# - Total units encapsulate residential units and commercial units, so the latter two can be removed.

# %%
columns_to_drop = [
    "borough",
    "tax_class_at_present",
    "block",
    "lot",
    "ease-ment",
    "address",
    "zip_code",
    "building_class_at_present",
    "tax_class_at_time_of_sale",
    "residential_units",
    "commercial_units",
    "building_class_at_time_of_sale",
    "sale_date",
    "building_class_category",
]

# %%
column = "sale_price"
boxplot_sorted(training_data, by="building_class_category", column=column)

# %% [markdown]
# The box plot above shows that building class category does have an influence on the sale price, but would be a pain to try and convert into a numerical value with all of the categories. With one hot encoding, it would take some effort to make sure the one hot encoded columns are the same for the training and the test data sets.

# %%
boxplot_sorted(training_data, by="neighborhood", column=column)

# %% [markdown]
# Too many neighbourhoods with a lot of outliers, make it difficult to use as a predictor.

# %%
columns_to_drop.append("neighborhood")

# Converting the apartment number into a boolean property given how they aren't always unique between different aprtments.
training_data.replace({"apartment_number": {np.nan: 0}}, inplace=True)
training_data.loc[
    training_data["apartment_number"] != 0, "apartment_number"
] = 1
training_data["apartment_number"] = training_data["apartment_number"].astype(
    int
)

training_data["apartment_number"]

# %%
# Preprocessing total units
training_data["total_units"].fillna(value=1, inplace=True)
training_data["total_units"] = training_data["total_units"].astype(int)

# %%
# Preprocessing the size related attributes.
training_data["land_square_feet"].fillna(
    value=training_data["land_square_feet"].mean(), inplace=True
)
training_data["gross_square_feet"].fillna(
    value=training_data["gross_square_feet"].mean(), inplace=True
)

# Taking the average year built.
training_data["year_built"].fillna(
    value=training_data["year_built"].mean(), inplace=True
)

# %%
training_data.drop(columns_to_drop, axis=1, inplace=True)

# %% [markdown]
# ### Answer to RQ1.3

# %%
training_data.corr(method="pearson")

# %% [markdown]
# It's surprising to see that the correlation between the gross square feet and the total units is very high (over 0.9). Let's drop the total number of units attribute.

# %%
columns_to_drop.append("total_units")
training_data.drop(["total_units"], axis=1, inplace=True)

# %% [markdown]
# ### Answer to RQ1.4
#
# - Attributes chosen:
#   - Apartment number (transformed into boolean)
#   - Land square feet
#   - Gross square feet
#   - Year built
#   - Building class at time of sale
#   - Sale Date

# %%
training_data.head()

# %% [markdown]
# ## Part 2: Prediction using Regression Models

# %%
test_data_1_df = test_data_1_df.dropna(subset=["sale_price"])
test_data_1_df = test_data_1_df[test_data_1_df["sale_price"] != 0]
test_data_2_df = test_data_2_df.dropna(subset=["sale_price"])
test_data_2_df = test_data_2_df[test_data_2_df["sale_price"] != 0]

# %%
test_data_1_df["sale_price"] = test_data_1_df["sale_price"] ** (1 / 5.2)
test_data_2_df["sale_price"] = test_data_2_df["sale_price"] ** (1 / 5.2)

# %%
test_data_1_df.replace({"apartment_number": {np.nan: 0}}, inplace=True)
test_data_1_df.loc[
    test_data_1_df["apartment_number"] != 0, "apartment_number"
] = 1
test_data_1_df["apartment_number"] = test_data_1_df["apartment_number"].astype(
    int
)
test_data_2_df.replace({"apartment_number": {np.nan: 0}}, inplace=True)
test_data_2_df.loc[
    test_data_2_df["apartment_number"] != 0, "apartment_number"
] = 1
test_data_2_df["apartment_number"] = test_data_2_df["apartment_number"].astype(
    int
)


# %%
test_data_1_df["land_square_feet"].fillna(
    value=test_data_1_df["land_square_feet"].mean(), inplace=True
)
test_data_1_df["gross_square_feet"].fillna(
    value=test_data_1_df["gross_square_feet"].mean(), inplace=True
)
test_data_1_df["year_built"].fillna(
    value=test_data_1_df["year_built"].mean(), inplace=True
)
test_data_2_df["land_square_feet"].fillna(
    value=test_data_2_df["land_square_feet"].mean(), inplace=True
)
test_data_2_df["gross_square_feet"].fillna(
    value=test_data_2_df["gross_square_feet"].mean(), inplace=True
)
test_data_2_df["year_built"].fillna(
    value=test_data_2_df["year_built"].mean(), inplace=True
)

# %%
test_data_1_df.drop(columns_to_drop, axis=1, inplace=True)
test_data_2_df.drop(columns_to_drop, axis=1, inplace=True)

# %%
test_data_1_df

# %%
training_data

# %% [markdown]
# ### Model 1

# %%
# Predict sale price using the training data and a linear regression model.
model_1 = sm.OLS(
    training_data["sale_price"], training_data.drop(["sale_price"], axis=1)
).fit()

model_1.summary()

# %%
predictions_1 = model_1.predict(test_data_1_df.drop(["sale_price"], axis=1))
rms = mean_squared_error(
    test_data_1_df["sale_price"], predictions_1, squared=False
)

rms

# %%
predictions_2 = model_1.predict(test_data_2_df.drop(["sale_price"], axis=1))
rms = mean_squared_error(
    test_data_2_df["sale_price"], predictions_2, squared=False
)

rms

# %% [markdown]
# ### Model 2

# %%

# %% [markdown]
# ### Results

# %%
